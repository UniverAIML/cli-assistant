# CLI Assistant

–°—É—á–∞—Å–Ω–∏–π CLI –∞—Å–∏—Å—Ç–µ–Ω—Ç –∑ AI-—á–∞—Ç –º–æ–∂–ª–∏–≤–æ—Å—Ç—è–º–∏ –¥–ª—è —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤ —Ä–æ–∑—Ä–æ–±–∫–∏.

## üöÄ –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ

- **AI-Powered Chat**: –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π —á–∞—Ç-–∞—Å–∏—Å—Ç–µ–Ω—Ç –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –≤–∏–∫–ª–∏–∫—É —Ñ—É–Ω–∫—Ü—ñ–π
- **–£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏**: –ü–æ–≤–Ω–∏–π CRUD –¥–ª—è –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤ –∑ –≤–∞–ª—ñ–¥–∞—Ü—ñ—î—é
- **–£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –Ω–æ—Ç–∞—Ç–∫–∞–º–∏**: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è, –ø–æ—à—É–∫ —Ç–∞ —Ä–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –Ω–æ—Ç–∞—Ç–æ–∫ –∑ —Ç–µ–≥–∞–º–∏
- **–ö—Ä–∞—Å–∏–≤–µ –º–µ–Ω—é**: –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–µ –º–µ–Ω—é –∑ –∫–æ–ª—å–æ—Ä–æ–≤–∏–º —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è–º
- **–ì–Ω—É—á–∫—ñ AI –º–æ–¥–µ–ª—ñ**: –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –ª–æ–∫–∞–ª—å–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π —Ç–∞ OpenAI API
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏ —Ç–∞ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è

## üñ•Ô∏è –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º —Ç–∞ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

–¶–µ–π CLI –∞—Å–∏—Å—Ç–µ–Ω—Ç –ø—ñ–¥—Ç—Ä–∏–º—É—î –∞–ø–∞—Ä–∞—Ç–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é.

### –í–∏–º–æ–≥–∏
- Python 3.9-3.13
- Poetry (–¥–ª—è —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—è–º–∏)
- –î–ª—è GPU –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è:
  - Windows/Linux: NVIDIA GPU –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é CUDA
  - macOS: Apple Silicon (M1/M2/M3/M4) –¥–ª—è MPS –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è

### –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
```bash
# –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ –≤—Å—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ —á–µ—Ä–µ–∑ Poetry
poetry install

# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è
poetry run cli-assistant --help
```

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏
–î–æ–¥–∞—Ç–æ–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î –≤–∞—à—É –ø–ª–∞—Ç—Ñ–æ—Ä–º—É —Ç–∞ –Ω–∞–ª–∞—à—Ç–æ–≤—É—î –æ–ø—Ç–∏–º–∞–ª—å–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è:
- **Windows/Linux + NVIDIA**: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î CUDA –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è
- **macOS Apple Silicon**: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Metal Performance Shaders (MPS)
- **–Ü–Ω—à—ñ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏**: –ü–æ–≤–µ—Ä—Ç–∞—î—Ç—å—Å—è –¥–æ CPU —Ä–µ–∂–∏–º—É

## üéØ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

```bash
# –ó–∞–ø—É—Å–∫ AI —á–∞—Ç-–∞—Å–∏—Å—Ç–µ–Ω—Ç–∞
poetry run cli-assistant
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç—É

```
cli-assistant/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ cli_assistant/              # –û—Å–Ω–æ–≤–Ω–∏–π –¥–æ–¥–∞—Ç–æ–∫
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # –¢–æ—á–∫–∞ –≤—Ö–æ–¥—É
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_assistant.py       # AI —á–∞—Ç —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ function_definitions.py # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è AI —Ñ—É–Ω–∫—Ü—ñ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_manager.py        # –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è AI –º–æ–¥–µ–ª—è–º–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config_manager.py       # –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ operations_manager.py   # –ë—ñ–∑–Ω–µ—Å-–ª–æ–≥—ñ–∫–∞ –æ–ø–µ—Ä–∞—Ü—ñ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ function_executor.py    # –í–∏–∫–æ–Ω–∞–≤–µ—Ü—å —Ñ—É–Ω–∫—Ü—ñ–π
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ interactive_menu.py     # –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–µ –º–µ–Ω—é
‚îÇ   ‚îú‚îÄ‚îÄ database/                   # –ú–æ–¥–µ–ª—ñ –¥–∞–Ω–∏—Ö
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contact_models.py       # –ú–æ–¥–µ–ª—ñ –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ note_models.py          # –ú–æ–¥–µ–ª—ñ –Ω–æ—Ç–∞—Ç–æ–∫
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_manager.py         # –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –¥–∞–Ω–∏–º–∏
‚îÇ   ‚îî‚îÄ‚îÄ personal_assistant.py       # –û—Å–Ω–æ–≤–Ω–∏–π –∫–ª–∞—Å –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞
‚îú‚îÄ‚îÄ tests/                          # –¢–µ—Å—Ç–∏
‚îú‚îÄ‚îÄ models/                         # –õ–æ–∫–∞–ª—å–Ω—ñ AI –º–æ–¥–µ–ª—ñ
‚îú‚îÄ‚îÄ pyproject.toml                  # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è Poetry
‚îî‚îÄ‚îÄ README.md                       # –¶—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ class_birthday_managment.py # Birthday functionality
‚îÇ   ‚îî‚îÄ‚îÄ notes_models/               # Note management (future)
‚îú‚îÄ‚îÄ tests/                          # Test suite
‚îú‚îÄ‚îÄ docs/                           # Documentation
‚îú‚îÄ‚îÄ pyproject.toml                  # Project configuration
‚îî‚îÄ‚îÄ README.md                       # This file
```

## ü§ñ AI Features

- **Function Calling**: AI can execute specific functions based on user intent
- **Context Awareness**: Maintains conversation history for better responses
- **Multi-Platform Optimization**: Automatic hardware detection and optimization

## üö® Troubleshooting

### GPU Not Detected
- **Windows**: Ensure NVIDIA drivers are updated, run `nvidia-smi`
- **macOS**: Check MPS availability: `python -c "import torch; print(torch.backends.mps.is_available())"`
- **Linux**: Verify CUDA installation and drivers

### Windows CUDA Issues
- Ensure NVIDIA drivers are up to date
- Check CUDA version compatibility
- Run `nvidia-smi` to verify GPU visibility

### macOS MPS Issues
- Requires macOS 12.3+
- Check with: `python -c "import torch; print(torch.backends.mps.is_available())"`


# Example environment configuration for CLI Assistant

# =============================================================================
# AI Provider Configuration
# =============================================================================

# Choose AI provider: "local" or "openai"

USE_OPENAI=true
# Hugging Face Token
HF_TOKEN=API_KEY

# =============================================================================
# OpenAI Configuration (only used when USE_OPENAI=true)
# =============================================================================
OPENAI_API_KEY=API_KEY
OPENAI_MODEL=gpt-4.1
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.1
OPENAI_TOP_P=1.0
OPENAI_TIMEOUT=30

# Available OpenAI models:
# - gpt-3.5-turbo (fast, cheap)
# - gpt-4 (high quality)
# - gpt-4-turbo (balanced)
# - gpt-4o (latest)

# =============================================================================
# Local Model Configuration (used when USE_OPENAI=false)
# =============================================================================
# These are handled by the existing config_manager.py
# Local model will be automatically detected based on your hardware:
# - Windows/Linux + NVIDIA GPU: Uses CUDA acceleration
# - macOS Apple Silicon: Uses MPS acceleration  
# - Other platforms: Falls back to CPU mode

# =============================================================================
# Usage Examples:
# =============================================================================
# For OpenAI API:
# 1. Set USE_OPENAI=true
# 2. Set your OPENAI_API_KEY
# 3. Choose OPENAI_MODEL
# 4. Run: poetry run cli-assistant

# For local models:
# 1. Set USE_OPENAI=false (default)
# 2. Run: poetry run cli-assistant
